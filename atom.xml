<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Flink in Practice</title>
  
  <subtitle>Hands-on and in-depth pratical examples and tutorials about Apache Flink and its ecosystem</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="//flinkinpractice.com/"/>
  <updated>2019-11-06T04:45:29.637Z</updated>
  <id>//flinkinpractice.com/</id>
  
  <author>
    <name>Liangjun Jiang (LJ)</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Implement Your Source: MySQL</title>
    <link href="//flinkinpractice.com/2019/11/05/Implement-Your-Source-MySQL/"/>
    <id>//flinkinpractice.com/2019/11/05/Implement-Your-Source-MySQL/</id>
    <published>2019-11-06T04:35:50.000Z</published>
    <updated>2019-11-06T04:45:29.637Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Set-up-MySQL-Environment"><a href="#Set-up-MySQL-Environment" class="headerlink" title="Set up MySQL Environment"></a>Set up MySQL Environment</h2><p>First of all, we need to have a MySQL database installed on your computer, or you can use MySQL Docker image, or even better, a <code>MySQL</code> docker image with a <code>[adminer](https://www.adminer.org/)</code> image. Here is the <code>stack.yml</code> file you can run with </p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose -f stack<span class="selector-class">.yml</span> up .</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="Code-with-IntelliJ"><a href="#Code-with-IntelliJ" class="headerlink" title="Code with IntelliJ"></a>Code with IntelliJ</h2><h3 id="Add-MySQL-Dependency"><a href="#Add-MySQL-Dependency" class="headerlink" title="Add MySQL Dependency"></a>Add MySQL Dependency</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>8.0.17<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Student-Model-Class"><a href="#Student-Model-Class" class="headerlink" title="Student Model Class"></a>Student Model Class</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lombok.AllArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"><span class="keyword">import</span> lombok.NoArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> lombok.ToString;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@ToString</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Student</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> id;</span><br><span class="line">  <span class="keyword">private</span> String name;</span><br><span class="line">  <span class="keyword">private</span> String password;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="MySQLSource-Class"><a href="#MySQLSource-Class" class="headerlink" title="MySQLSource Class"></a>MySQLSource Class</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.RichSourceFunction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.DriverManager;</span><br><span class="line"><span class="keyword">import</span> java.sql.PreparedStatement;</span><br><span class="line"><span class="keyword">import</span> java.sql.ResultSet;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MySQLSource</span> <span class="keyword">extends</span> <span class="title">RichSourceFunction</span>&lt;<span class="title">Student</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    PreparedStatement ps;</span><br><span class="line">    <span class="keyword">private</span> Connection connection;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * open() : build connection so we don't have to do it in every invoke</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> parameters</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.open(parameters);</span><br><span class="line">        connection = getConnection();</span><br><span class="line">        String sql = <span class="string">"select * from student;"</span>;</span><br><span class="line">        ps = <span class="keyword">this</span>.connection.prepareStatement(sql);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 程序执行完毕就可以进行，关闭连接和释放资源的动作了</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.close();</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (ps != <span class="keyword">null</span>) &#123;</span><br><span class="line">            ps.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;Student&gt; sourceContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ResultSet resultSet = ps.executeQuery();</span><br><span class="line">        <span class="keyword">while</span> (resultSet.next()) &#123;</span><br><span class="line">            Student student = <span class="keyword">new</span> Student(</span><br><span class="line">                    resultSet.getInt(<span class="string">"id"</span>),</span><br><span class="line">                    resultSet.getString(<span class="string">"name"</span>).trim(),</span><br><span class="line">                    resultSet.getString(<span class="string">"password"</span>).trim(),</span><br><span class="line">                    resultSet.getInt(<span class="string">"age"</span>));</span><br><span class="line">            sourceContext.collect(student);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Connection <span class="title">getConnection</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Connection con = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            con = DriverManager.getConnection(<span class="string">"jdbc:mysql://localhost:3306/flinkinpratice?useUnicode=true&amp;characterEncoding=UTF-8"</span>, <span class="string">"root"</span>, <span class="string">"example"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.out.println(<span class="string">"-----------mysql get connection has exception , msg = "</span>+ e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> con;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="MySQLAsSource-Class"><a href="#MySQLAsSource-Class" class="headerlink" title="MySQLAsSource Class"></a>MySQLAsSource Class</h3><p>Finally, the Flink Application</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MySQLAsSource</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.addSource(<span class="keyword">new</span> MySQLSource()).print();</span><br><span class="line">        env.execute(<span class="string">"MySQL as Flink Source"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>That’s it.</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Set-up-MySQL-Environment&quot;&gt;&lt;a href=&quot;#Set-up-MySQL-Environment&quot; class=&quot;headerlink&quot; title=&quot;Set up MySQL Environment&quot;&gt;&lt;/a&gt;Set up MySQL Environment&lt;/h2&gt;&lt;p&gt;First of all, we need to have a MySQL database installed on your computer, or you can use MySQL Docker image, or even better, a &lt;code&gt;MySQL&lt;/code&gt; docker image with a &lt;code&gt;[adminer](https://www.adminer.org/)&lt;/code&gt; image. Here is the &lt;code&gt;stack.yml&lt;/code&gt; file you can run with &lt;/p&gt;
&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;docker-compose -f stack&lt;span class=&quot;selector-class&quot;&gt;.yml&lt;/span&gt; up .&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
    
      <category term="Flink" scheme="//flinkinpractice.com/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch as Sinker</title>
    <link href="//flinkinpractice.com/2019/10/29/ElasticSearch-as-Sinker/"/>
    <id>//flinkinpractice.com/2019/10/29/ElasticSearch-as-Sinker/</id>
    <published>2019-10-30T01:25:53.000Z</published>
    <updated>2019-11-02T13:08:23.272Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Flink is commonly used for log analysis. System or Application logs are sent to Kafka topics, computed by Apache Flink to generate new Kafka messages, consumed by other systems. ElasticSearch, Logstash and Kibana (ELK) Stack is a common system to analyze logs. The powerful search feature of ElasticSearch helps find the point of interest, the Kibana is useful for visualizing and project tracking. </p><p>In this chapter, we will introduce Elastic Search as a sinker.</p><a id="more"></a><p>Keep in mind, this guide needs to be followed by the <em><a href="https://www.flinkinpractice.com/2019/10/29/Set-up-Local-Kafka-Development-Environment/" target="_blank" rel="noopener">Set up Local Kafka Development Environment</a></em></p><h2 id="Set-up-ELK-stack"><a href="#Set-up-ELK-stack" class="headerlink" title="Set up ELK stack"></a>Set up ELK stack</h2><p>The easiest way to setup ELK stack is to use this <code>docker-elk</code> <a href="https://github.com/deviantony/docker-elk" target="_blank" rel="noopener">github repo</a>. Once you clone this repo to you local Mac computer. All you need to do is to run</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">docker-compose up</span></span><br></pre></td></tr></table></figure><p>Your Kibana web application will be running on <code>localhost:5601</code>. Keep in mind that it might take a while for all applications ready. </p><p>You can use </p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">docker-compose down</span></span><br></pre></td></tr></table></figure><p>to take down the ELK stack, and remove all containers.</p><h2 id="ElasticSearch-Sinker"><a href="#ElasticSearch-Sinker" class="headerlink" title="ElasticSearch Sinker"></a>ElasticSearch Sinker</h2><p>In this example, we will continue the MySQL as Sinker example illustrated earlier. Now we will write out Student data into Elastic Search instead this time. </p><ol><li>ElasticSearch Connector dependency<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-elasticsearch6_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="application-properties"><a href="#application-properties" class="headerlink" title="application.properties"></a>application.properties</h2><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kafka.brokers=localhost:<span class="number">9092</span></span><br><span class="line">kafka.<span class="keyword">group</span>.id=metrics-<span class="keyword">group</span>-test</span><br><span class="line">kafka.zookeeper.<span class="keyword">connect</span>=localhost:<span class="number">2181</span></span><br><span class="line">metrics.topic=alert-metrics</span><br><span class="line">stream.parallelism=<span class="number">5</span></span><br><span class="line">stream.<span class="keyword">checkpoint</span>.interval=<span class="number">1000</span></span><br><span class="line">stream.<span class="keyword">checkpoint</span>.<span class="keyword">enable</span>=<span class="keyword">false</span></span><br><span class="line">elasticsearch.hosts=localhost:<span class="number">9200</span>,localhost:<span class="number">9202</span>,localhost:<span class="number">9203</span></span><br><span class="line">elasticsearch.bulk.flush.max.actions=<span class="number">40</span></span><br><span class="line">stream.sink.parallelism=<span class="number">5</span></span><br></pre></td></tr></table></figure><h2 id="Start-Kafka-with-Zookeeper"><a href="#Start-Kafka-with-Zookeeper" class="headerlink" title="Start Kafka with Zookeeper"></a>Start Kafka with Zookeeper</h2><p>We have covered how to start Kafka with Zookeeper in the previous chapter. You can start it now.</p><h2 id="Student-Class-and-Write-to-Kafka-Utility-Class"><a href="#Student-Class-and-Write-to-Kafka-Utility-Class" class="headerlink" title="Student Class and Write to Kafka Utility Class"></a>Student Class and Write to Kafka Utility Class</h2><p>Similar in the previous chapter, we have <code>Student.java</code> class and <code>KafkaUtils.java</code>. The purpose of <code>KafkaUtils.java</code> is to publish messages to Kafka so our Flink application has something to consume.</p><h2 id="Main-Class"><a href="#Main-Class" class="headerlink" title="Main Class"></a>Main Class</h2><p>We create a <code>Main.java</code> class to emulate the process. </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.RuntimeContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpHost;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.auth.AuthScope;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.auth.UsernamePasswordCredentials;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.client.CredentialsProvider;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.impl.client.BasicCredentialsProvider;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.impl.nio.client.HttpAsyncClientBuilder;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.message.BasicHeader;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.action.index.IndexRequest;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.Requests;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.client.RestClientBuilder;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String READ_TOPIC = <span class="string">"student-1"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</span><br><span class="line">        props.put(<span class="string">"zookeeper.connect"</span>, <span class="string">"localhost:2181"</span>);</span><br><span class="line">        props.put(<span class="string">"group.id"</span>, <span class="string">"student-group-1"</span>);</span><br><span class="line">        props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(<span class="string">"auto.offset.reset"</span>, <span class="string">"latest"</span>);</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;String&gt; student = env.addSource(<span class="keyword">new</span> FlinkKafkaConsumer&lt;&gt;(</span><br><span class="line">                READ_TOPIC,</span><br><span class="line">                <span class="keyword">new</span> SimpleStringSchema(),</span><br><span class="line">                props)).setParallelism(<span class="number">1</span>);</span><br><span class="line">        student.print();</span><br><span class="line">        log.info(<span class="string">"student:"</span> + student);</span><br><span class="line">        List&lt;HttpHost&gt; esHttphost = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        esHttphost.add(<span class="keyword">new</span> HttpHost(<span class="string">"127.0.0.1"</span>, <span class="number">9200</span>, <span class="string">"http"</span>));</span><br><span class="line"></span><br><span class="line">        ElasticsearchSink.Builder&lt;String&gt; esSinkBuilder = <span class="keyword">new</span> ElasticsearchSink.Builder&lt;&gt;(</span><br><span class="line">                esHttphost,</span><br><span class="line">                <span class="keyword">new</span> ElasticsearchSinkFunction&lt;String&gt;() &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> IndexRequest <span class="title">createIndexRequest</span><span class="params">(String element)</span> </span>&#123;</span><br><span class="line">                        Map&lt;String, String&gt; json = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">                        json.put(<span class="string">"data"</span>, element);</span><br><span class="line">                        log.info(<span class="string">"data:"</span> + element);</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">return</span> Requests.indexRequest()</span><br><span class="line">                                .index(<span class="string">"index-student"</span>)</span><br><span class="line">                                .type(<span class="string">"student"</span>)</span><br><span class="line">                                .source(json);</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(String element, RuntimeContext ctx, RequestIndexer indexer)</span> </span>&#123;</span><br><span class="line">                        indexer.add(createIndexRequest(element));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        esSinkBuilder.setBulkFlushMaxActions(<span class="number">1</span>);</span><br><span class="line">        esSinkBuilder.setRestClientFactory(restClientBuilder -&gt; &#123;</span><br><span class="line">            restClientBuilder.setDefaultHeaders(<span class="keyword">new</span> BasicHeader[]&#123;<span class="keyword">new</span> BasicHeader(<span class="string">"Content-Type"</span>,<span class="string">"application/json"</span>)&#125;);</span><br><span class="line">            restClientBuilder.setHttpClientConfigCallback(<span class="keyword">new</span> RestClientBuilder.HttpClientConfigCallback() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> HttpAsyncClientBuilder <span class="title">customizeHttpClient</span><span class="params">(HttpAsyncClientBuilder httpClientBuilder)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// elastic search username and password</span></span><br><span class="line">                    CredentialsProvider credentialsProvider = <span class="keyword">new</span> BasicCredentialsProvider();</span><br><span class="line">                    credentialsProvider.setCredentials(AuthScope.ANY, <span class="keyword">new</span> UsernamePasswordCredentials(<span class="string">"elastic"</span>, <span class="string">"changeme"</span>));</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">return</span> httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        esSinkBuilder.setFailureHandler(<span class="keyword">new</span> ElasticSearchSinkUtil.RetryRejectedExecutionFailureHandler());</span><br><span class="line"></span><br><span class="line">        student.addSink(esSinkBuilder.build());</span><br><span class="line">        env.execute(<span class="string">"Kafka as source, elastic search as sinker"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Validate-the-Results"><a href="#Validate-the-Results" class="headerlink" title="Validate the Results"></a>Validate the Results</h2><p>Head to <code>localhost:5601</code> to Kibana, log into the dashboard with <code>elastic</code> and <code>changeme</code> as username and password. The pair of credentials is the default. You might also notice we use those to authenticate with Elastic Search in the previous section. </p><p>Click <code>Dev Tools</code> in the left sidebar, Type the following and run it (click the green button next to the query string)</p><p><img src="https://mlflowexperiments.blob.core.windows.net/flink-in-practice-blog/es-as-sinker-validate.png" alt="elasticsearch as sinker validating"></p><p>Now you see the <em>index-student</em> has been indexed by Elastic Search. You want to see the student’s records. We have another query available shown in the screen above. Now you run.</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /<span class="built_in">index</span>-student/_<span class="built_in">search</span>?pretty</span><br></pre></td></tr></table></figure><p>You will see some results as follows:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">.....</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"took"</span> : <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"timed_out"</span> : <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">"_shards"</span> : &#123;</span><br><span class="line">    <span class="attr">"total"</span> : <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"successful"</span> : <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"skipped"</span> : <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"failed"</span> : <span class="number">0</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"hits"</span> : &#123;</span><br><span class="line">    <span class="attr">"total"</span> : &#123;</span><br><span class="line">      <span class="attr">"value"</span> : <span class="number">100</span>,</span><br><span class="line">      <span class="attr">"relation"</span> : <span class="string">"eq"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"max_score"</span> : <span class="number">1.0</span>,</span><br><span class="line">    <span class="attr">"hits"</span> : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"index-student"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"student"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"nYLvvG0BlJ_Mznd3q8Ty"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">1.0</span>,</span><br><span class="line">        <span class="attr">"_source"</span> : &#123;</span><br><span class="line">          <span class="attr">"data"</span> : <span class="string">""</span><span class="string">"&#123;"</span>id<span class="string">":12,"</span>name<span class="string">":"</span>itzzy12<span class="string">","</span>password<span class="string">":"</span>password12<span class="string">","</span>age<span class="string">":30&#125;"</span><span class="string">""</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>It proves our Flink application has successfully consumed Kafka messages, and write to Elastic Search.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Flink is commonly used for log analysis. System or Application logs are sent to Kafka topics, computed by Apache Flink to generate new Kafka messages, consumed by other systems. ElasticSearch, Logstash and Kibana (ELK) Stack is a common system to analyze logs. The powerful search feature of ElasticSearch helps find the point of interest, the Kibana is useful for visualizing and project tracking. &lt;/p&gt;
&lt;p&gt;In this chapter, we will introduce Elastic Search as a sinker.&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Flink" scheme="//flinkinpractice.com/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Set up Local Kafka Development Environment</title>
    <link href="//flinkinpractice.com/2019/10/29/Set-up-Local-Kafka-Development-Environment/"/>
    <id>//flinkinpractice.com/2019/10/29/Set-up-Local-Kafka-Development-Environment/</id>
    <published>2019-10-29T19:25:19.000Z</published>
    <updated>2019-11-01T03:48:02.145Z</updated>
    
    <content type="html"><![CDATA[<p>In this tutorial, we will walk through one way to set up a local Kafka development environment, and demonstrate some common commands to use Kafka. We belive those commands are important for you later to develop and debug your Flink applications.</p><a id="more"></a><ol><li><p>Download the Binary</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/Download</span><br><span class="line">curl -o kafka_2.11-2.3.0.tgz http://www.trieuvan.com/apache/kafka/2.3.0/kafka_2.11-2.3.0.tgz</span><br></pre></td></tr></table></figure></li><li><p>Untar </p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2<span class="number">.11</span><span class="number">-2.3</span><span class="number">.0</span>.tgz</span><br><span class="line">cd ~/kafka_2<span class="number">.11</span><span class="number">-2.3</span><span class="number">.0</span>/</span><br></pre></td></tr></table></figure></li><li><p>Configuration </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/config/server.properties</span><br></pre></td></tr></table></figure></li></ol><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">broker.id</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">log.dir</span>=~/kafka-log/</span><br></pre></td></tr></table></figure><ol start="4"><li><p>Start Single Kafka Instance</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zookeeper-<span class="keyword">server</span>-<span class="keyword">start</span>.sh -daemon config/zookeeper.properties</span><br></pre></td></tr></table></figure></li><li><p>Start Kafka Service</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-<span class="keyword">server</span>-<span class="keyword">start</span>.sh  config/<span class="keyword">server</span>.properties</span><br></pre></td></tr></table></figure></li><li><p>Create a Single Partition Single Replication Topic</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">bin/kafka</span><span class="literal">-</span><span class="comment">topics</span><span class="string">.</span><span class="comment">sh</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">create</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">zookeeper</span> <span class="comment">localhost:2181</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">replication</span><span class="literal">-</span><span class="comment">factor</span> <span class="comment">1</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">partitions</span> <span class="comment">1</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">topic</span> <span class="comment">test</span></span><br></pre></td></tr></table></figure></li><li><p>List Topics</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.<span class="keyword">sh</span> --<span class="keyword">list</span> --zookeeper localhos<span class="variable">t:2181</span></span><br></pre></td></tr></table></figure><p>You are expected to see:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">test</span></span><br></pre></td></tr></table></figure></li><li><p>Produce a Message to a Topic</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.<span class="keyword">sh</span> --broker-<span class="keyword">list</span> localhost:9092 --topic <span class="keyword">test</span></span><br></pre></td></tr></table></figure><p>then type:</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hello</span> <span class="string">world</span></span><br><span class="line"><span class="attr">hello</span> <span class="string">kafka</span></span><br><span class="line"><span class="attr">apache</span> <span class="string">spark</span></span><br><span class="line"><span class="attr">apache</span> <span class="string">flink</span></span><br></pre></td></tr></table></figure></li><li><p>Consume Messages from Beginning</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">hello world</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">hello kafka</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">apache spark</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">apche flink</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"></span></span><br></pre></td></tr></table></figure></li><li><p>Inspect a Topic</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">bin/kafka-topics.sh</span> <span class="bullet">--describe</span> <span class="bullet">--zookeeper</span> <span class="attr">localhost:2181</span> <span class="bullet">--topic</span> <span class="string">test</span></span><br><span class="line"><span class="attr">Topic:</span><span class="string">test</span><span class="attr">PartitionCount:1</span><span class="attr">ReplicationFactor:1</span><span class="attr">Configs:</span></span><br><span class="line"><span class="attr">Topic:</span> <span class="string">test</span><span class="attr">Partition:</span> <span class="number">0</span><span class="attr">Leader:</span> <span class="number">1</span><span class="attr">Replicas:</span> <span class="number">1</span><span class="attr">Isr:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p>Inspect messages Under a topic</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">bin/kafka</span><span class="literal">-</span><span class="comment">console</span><span class="literal">-</span><span class="comment">consumer</span><span class="string">.</span><span class="comment">sh</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">bootstrap</span><span class="literal">-</span><span class="comment">server</span> <span class="comment">localhost:9092</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">topic</span> <span class="comment">test</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">from</span><span class="literal">-</span><span class="comment">beginning</span></span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In this tutorial, we will walk through one way to set up a local Kafka development environment, and demonstrate some common commands to use Kafka. We belive those commands are important for you later to develop and debug your Flink applications.&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Flink" scheme="//flinkinpractice.com/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Book Review: Stream Processing with Apache Flink</title>
    <link href="//flinkinpractice.com/2019/10/10/Book-Review-Stream-Processing-with-Apache-Flink/"/>
    <id>//flinkinpractice.com/2019/10/10/Book-Review-Stream-Processing-with-Apache-Flink/</id>
    <published>2019-10-10T21:35:02.000Z</published>
    <updated>2019-11-01T03:51:02.621Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://miro.medium.com/max/1000/1*wp57DdCLpsQGAinYm5PfXQ.jpeg" alt="Book Cover: Stream Processing with Apache Flink"></p><p>An excellent book about Fink fundamentals. Can be a good reference book.</p><a id="more"></a><h2 id="Chapter-1"><a href="#Chapter-1" class="headerlink" title="Chapter 1:"></a>Chapter 1:</h2><p>What’s stateful stream processing<br>Why stateful — 1. for event driven application, 2 data pipeline application, 3 data analytics application<br>how stateful — checkpoint and exact-once</p><h2 id="Chapter-2-Stream-Processing-Fundamentals"><a href="#Chapter-2-Stream-Processing-Fundamentals" class="headerlink" title="Chapter 2: Stream Processing Fundamentals"></a>Chapter 2: Stream Processing Fundamentals</h2><p>Dataflow programming — dataflow graph &amp; daa parallelism &amp; task parallelism<br>Data exchange strategies — forward strategy, broadcast strategy, key-based strategy and random strategy<br>Processing streams in Parallel : Latency, throughput,<br>Operations on Data stream: stateless or stateful<br>Data ingestion and data egress — data ingestion from data sources (for example, kafaka topic), data egress to data sinks, for example, files, databases, message queues, etc<br>Transformation operations —<br>Rolling aggregation operation<br>Window operation — finite set of events called buckets; tumbling windows (count based, time based, session window such as user analytics),<br>Time semantics — processing time, event time and watermarks — a global progress metric that indicates the point in time when we are confident that no more delayed events will arrive<br>State and consistency models — state management, state partitioning, state recovery<br>Task Failures —<br>Result Guarantees — at-most-once, at-least-once, exactly-once, end-to-end exactly-once</p><h2 id="Chapter-3-Architecture"><a href="#Chapter-3-Architecture" class="headerlink" title="Chapter 3: Architecture"></a>Chapter 3: Architecture</h2><p>System Architecture — leader election of highly available : Zookeeper; Apache Mesos, YARN, Kubernetes; HDFS, S3; RocksDB<br>Components of A Flink — a JobManager, a ResourceManager, a TaskManager, and a Dispatcher<br>JobManager — JobGraph, a logical dataflow graph (Execution Graph), and a JAR file.<br>TaskManagers — workers progresses of Flink<br>Dispatcher — runs across job execution<br>Deployment — Framework style (submitted your job as a Jar) and Library Style (bundle Flink and your job as a docker image)<br>Task Execution — Operators, tasks and processing slots<br>High Available Setup — zookeeper<br>TaskManager failures — JobManger ass ResourcesManager to provide more<br>JobManager failures — recover from ZooKeeper<br>Data Transfer in Flink — credit based flow control, task chaining,<br>Event-time processing — timestamp<br>Watermark propagation and event time —<br>Timestamp Assignment and watermark generation-<br>State management — operator state — list state, union list state, and broadcast state<br>Keyed state — value state, list state, and map state<br>state backends — local statement management and checkpointing state to a remote location<br>Scaling stateful operators -<br>Checkpoints, savepoints and state recovery — consistent checkpoints, recovery from a consistent checkpoint<br>Flink’s checkpointing algorithm — checkpoint barrier — carriers a checkpoint Id to identify the checkpoint it belongs to and logically splits a stream into two parts.<br>Performance Implications of Checkpointing —<br>Savepoints —<br>Using Savepoints — starting an application from a savepoint</p><h2 id="Chapter-4-Setting-up-a-Development-Environment-for-Apache-Flink"><a href="#Chapter-4-Setting-up-a-Development-Environment-for-Apache-Flink" class="headerlink" title="Chapter 4 Setting up a Development Environment for Apache Flink"></a>Chapter 4 Setting up a Development Environment for Apache Flink</h2><h2 id="Chapter-5-The-DataStream-API"><a href="#Chapter-5-The-DataStream-API" class="headerlink" title="Chapter 5 The DataStream API"></a>Chapter 5 The DataStream API</h2><p>Typical stream application: 1. set up the execution environment, 2. read one or more streams from data sources 3. Apply stream transformation to implement the application logic 4. Optionally output the result to one or more data sinks 5. execute the program<br>Transformations — Basic transformation (map, filter, flatmap), keyedstream, multistream transformation (merge multiple stream into one stream or split one stream into multiple streams, keyBy, Rolling Aggregations — sum(), min(), max(),minBy(),maxBy(), reduce; Multistream Transformation — Union, Connect, CoMap, and CoFlatMap, Split and select), distribution transformation reorganize stream events (Random, Round-Robin, Rescale, Broadcast, Global, Custom)<br>Setting Parallelism —<br>Types — data types (primitive, java &amp; scala tuples, POJOs, special), Kryo serialization<br>Defining Keys and Referencing Fields (Field positions, field expressions, key selectors)<br>Implementing functions — function classes, function must be Java serializable, lambada functions, Rich functions<br>Including external and flink dependencies — 1. bundle all dependencies into an application JAR (flatted JAR, preferred way) 2. the Jar file of a dependency can be added to the ./lib folder.</p><h2 id="Chapter-6-—-Time-based-and-window-operators"><a href="#Chapter-6-—-Time-based-and-window-operators" class="headerlink" title="Chapter 6 — Time based and window operators"></a>Chapter 6 — Time based and window operators</h2><p>Configuring time characteristics — processingTime, EventTime, IngestionTime<br>Assigning Timestamps and Generating Watermarks —<br>Watermarks, Latency and completeness —<br>Process Functions —<br>TimerServices and Timers —<br>Window Operators —<br>Defining Window Operators —<br>Built-in Window Assigners — tumbling windows, sliding windows, session windows<br>Applying Functions to Windows<br>Reduce Function —<br>ProcessWindow Function —<br>Incremental Aggregation and ProcessWindow function —<br>Customizing Window Operators —<br>Window Lifecycle — window content, window object, custom-defined state in a trigger<br>Window Assigners —<br>Triggers — continue, fire, purge, fire_and_purge<br>Evictors —<br>Joining Streams on Time — Interval Join, window join<br>Handling Late Data — Dropping Late Events, Redirecting Late Events, Updating Results by including Late Events</p><h2 id="Chapter-7-Stateful-Operators-and-Applications"><a href="#Chapter-7-Stateful-Operators-and-Applications" class="headerlink" title="Chapter 7. Stateful Operators and Applications"></a>Chapter 7. Stateful Operators and Applications</h2><p>Implementing Stateful Functions —<br>— Declaring Keyed State at RuntimeContext , ValueState, ListState, MapState, ReducingState, AggregatingState,<br>Implementing Operator List State with the ListCheckpointed Interface, SnapshotState(), restoreState(),<br>Using Connected Broadcast State —<br>Using the CheckpointedFunction interface<br>Receiving Notification About Completed Checkpoints<br>Enabling Failure Recovery for Stateful Applications<br>Ensuring the Maintainability of Stateful Applications — operators unique identifiers and maxium parallelism are baked into savepoints<br>Specifiying Unique Operator Identifiers —<br>Choosing a State Backend — MemoryStateBackend, FsStateBackend, RocksDBStateBackend<br>Choosing a State Primitive — ValueState, ListState, and MapState,<br>Preventing Leaking State —<br>you should take application requirements and the properties of its input data, such as key domain, into account when designing and implement- ing stateful operators.<br>Evolving Stateful Applications —</p><ol><li>Updating an application without modifying existing state</li><li>Removing a state from the application</li><li>modifying the state of an existing operator by changing the state primitive or data type of the state<br>Queryable State —<br>need to share their results with other applications. A common pattern is to write results into a database or key-value store and have other applications retrieve the result from that datastore. Such an architecture implies that a separate system needs to be set up and maintained, which can be a major effort, especially if this needs to be a distributed system as well.<br>Architecture and Enabling Queryable State: 3 processes. 1. the QueryablestateClient is used by an external app to submit queries and retrieve results</li><li>queryableStateClientProxy accepts and serves client requests.</li><li>queryableStateServer serves the requests of a client proxy.<br>Exposing queryable state<br>Querying State from external applications</li></ol><h2 id="Chapter-8-Reading-from-and-Writing-to-External-Systems"><a href="#Chapter-8-Reading-from-and-Writing-to-External-Systems" class="headerlink" title="Chapter 8. Reading from and Writing to External Systems"></a>Chapter 8. Reading from and Writing to External Systems</h2><p>However, just being able to read or write data to external datastores is not sufficient for a stream processor that wants to provide meaningful consistency guarantees in the case of failure.<br>Applications Consistency Guarantees — Instead, the source and sink connectors of an application need to be integrated with Flink’s checkpointing and recovery mechanism and provide certain properties to be able to give meaningful guarantees.If an application ingests data from a source connector that is not able to store and reset a reading position, it might suffer from data loss in the case of a failure and only provide at-most-once guarantees.<br>Idempotent Writes-<br>Transactional Writes-write-ahead-log(WAL)sink (At least once)and two-phase-commit(2pc) sink(exactly once)<br>Provided Connectors — provides connetors for Kafka, Kinesis, RabbitMQ….<br>Apache Kafka Source Connector (Sinker) connector, at-least-once guarantees for the kafka sink, exactly-once guarantees for kafka sink, custom partitioning and writing message timestamps, filesystem source connector, Filesystem sink connector,<br>Apache Cassandra Sink Connector<br>Implementing a custom source function,<br>Resettable source functions<br>source functions, timestamps, and watermarks<br>implementing a custom sink function<br>Idempotent Sink Connectors<br>Transactional Sink Connectors<br>GenericWriteAheadSink<br>TwoPhaseCommitSinkFunction<br>Asynchronously Accessing External Systems</p><h2 id="Chapter-9-Setting-Up-Flink-for-Streaming-Applications"><a href="#Chapter-9-Setting-Up-Flink-for-Streaming-Applications" class="headerlink" title="Chapter 9. Setting Up Flink for Streaming Applications"></a>Chapter 9. Setting Up Flink for Streaming Applications</h2><p>Deployment Modes: Standalone Cluster, Docker, Apache Hadoop YARN, Kubernetes<br>Highly Available Setups — zooKeeper setup<br>HA standalone Setup<br>HA Yarn Setup<br>HA K8S setup<br>Integration with Hadoop Components<br>Filesystem Configuration: Local Filesystem, Hadoop HDFS, Amazon S3 and OpenStack Swift FS<br>System Configuration — Java and classloading, CPU, memory and network buffers, Disk Storage, Checkpointing and State Backends, Security — Kerberos authentication,<br>Chapter 10. Operating Flink and Streaming Applications<br>Running and Managing Streaming Applications — most of these features are based on SavePoints.<br>Managing Applications with the command-line client<br>Starting an application<br>Listing running applications<br>taking and disposing of a savepoint<br>Cancelling an application<br>Starting an application from a savepoint<br>scaling an application in and out<br>managing applications with REST API<br>Managing and monitoring a flink Cluster<br>Managing and monitoring a flink applications<br>Bundling and deploying application in containers —<br>Building a job-specific flink docker image<br>running a job-specific docker image on kubernetes<br>Controlling task scheduling, controlling task chaining, defining slot-sharing groups, tuning checkpointing and recovery (configuring checkpointing, enabling checkpoint compression, retaining checkpoints after an application stopped, configuring state backends, configuring recovery, restart strategies, local recovery<br>Monitoring Flink Cluster and applications — flink web UI, Metric System, Registring and Using Metircs, Metric Groups, monitoring latency,<br>Configuring the logging behavior-<br>Chapter 11: where to go from here<br>domain-specific libraries, and API for relational queries, complex event processing (CEP) and graph processing<br>The DataSet API for batching Processing<br>Table API and SQL for Relational Analysis<br>FlinkCEP for Complex Event Processing and Pattern Matching<br>Gelly for Graph Processing</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1000/1*wp57DdCLpsQGAinYm5PfXQ.jpeg&quot; alt=&quot;Book Cover: Stream Processing with Apache Flink&quot;&gt;&lt;/p&gt;
&lt;p&gt;An excellent book about Fink fundamentals. Can be a good reference book.&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Flink" scheme="//flinkinpractice.com/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Processing Time and Windows Explained by Examples</title>
    <link href="//flinkinpractice.com/2019/09/29/Windows-Explained-by-Examples/"/>
    <id>//flinkinpractice.com/2019/09/29/Windows-Explained-by-Examples/</id>
    <published>2019-09-30T01:25:17.000Z</published>
    <updated>2019-11-01T03:49:53.589Z</updated>
    
    <content type="html"><![CDATA[<p><em>Time</em> and <em>Windows</em> are two basic and important concepts in Apache Flink. Apache Flink is able to handle:</p><ol><li>Processing Time</li><li>Event Time</li><li>Ingestion Time</li></ol><p>On the other hand, Apache Flink provides different <em>windows</em> oepration:</p><ol><li>Tumbling Window</li><li>Sliding Window</li><li>Session Window</li></ol><a id="more"></a><p>The rich <em>Windows</em> APIs of Apache Flink make it possible to handle all possible operation while combining <em>Processing Time</em> and <em>Windows</em>. In this blog, we use code snippet to demonstrate the difference.</p><p>In addition, there is another way to define a window characteristic: Count. We also include an example of count based window operation.</p><h2 id="Processing-Time"><a href="#Processing-Time" class="headerlink" title="Processing Time"></a>Processing Time</h2><ol><li><p>Keyed and Processing Time based Tumbling Windows</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// keyed and processing time based tumbling window</span></span><br><span class="line">data.flatMap(<span class="keyword">new</span> LineSplitter())</span><br><span class="line">    .keyBy(<span class="number">1</span>)</span><br><span class="line">    .timeWindow(Time.seconds(<span class="number">30</span>))</span><br><span class="line">    .sum(<span class="number">0</span>)</span><br><span class="line">    .print();</span><br></pre></td></tr></table></figure><p>You enter</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">2 </span>tiger</span><br><span class="line"><span class="symbol">3 </span>tigers</span><br><span class="line"><span class="symbol">4 </span>tigers</span><br></pre></td></tr></table></figure><p>wait for 30 seconds, you will see the terminal output</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">9</span>,tigers)</span><br></pre></td></tr></table></figure></li><li><p>Keyed and Processing Time based Sliding Windows</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data.flatMap(<span class="keyword">new</span> LineSplitter())</span><br><span class="line">    .keyBy(<span class="number">1</span>)</span><br><span class="line">    .timeWindow(Time.seconds(<span class="number">10</span>), Time.seconds(<span class="number">5</span>))</span><br><span class="line">    .sum(<span class="number">0</span>)</span><br><span class="line">    .print();</span><br></pre></td></tr></table></figure><p>You have window size of 10 seconds, and the sliding window size of 5 seconds. It means each 5 seconds, get the sum of input of last 10 seconds. To verify this, it is a little bit tricky. Besides the <code>nc</code> terminal you have in the previous example, you also need to have a timer. Or you can count the elapsed seconds in your brain. For example, if you enter continuously,</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">2 </span>lions</span><br><span class="line"><span class="symbol">2 </span>lions</span><br></pre></td></tr></table></figure><p>In approximate 5 seconds, you will see output</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">4</span>,lions)</span><br></pre></td></tr></table></figure><p>Then in another approximate 5 seconds, you will see another output</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">4</span>,lions)</span><br></pre></td></tr></table></figure><p>What’s the use case of <em>sliding window</em>? </p></li><li><p>Keyed and Count based Tumbling Window</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// keyed and count based on tumbling window</span></span><br><span class="line">data.flatMap(<span class="keyword">new</span> LineSplitter())</span><br><span class="line">    .keyBy(<span class="number">1</span>)</span><br><span class="line">    .countWindow(<span class="number">3</span>)</span><br><span class="line">    .sum(<span class="number">0</span>)</span><br><span class="line">    .print();</span><br></pre></td></tr></table></figure><p>Do the sum for the last 3 items. </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2 cats</span><br><span class="line">2 cats</span><br><span class="line">3 cats</span><br><span class="line">4 cats</span><br></pre></td></tr></table></figure><p>The output will be:</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">7</span>,cats)</span><br></pre></td></tr></table></figure></li><li><p>Keyed and Count based Sliding Window</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  keyed and count based on sliding window</span></span><br><span class="line">data.flatMap(<span class="keyword">new</span> LineSplitter())</span><br><span class="line">    .keyBy(<span class="number">1</span>)</span><br><span class="line">    .countWindow(<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">    .sum(<span class="number">0</span>)</span><br><span class="line">    .print();</span><br></pre></td></tr></table></figure><p>This is sum the last 4 items for each 3 items. Since this is keyed operation, it needs to have the same key to be counted. For example, your input is</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">2 </span>cats</span><br><span class="line"><span class="symbol">3 </span>dogs</span><br><span class="line"><span class="symbol">5 </span>lions</span><br><span class="line"><span class="symbol">6 </span>tigers</span><br></pre></td></tr></table></figure><p>You will expect nothing to be happened.<br>If you continue to enter</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">7 </span>mice</span><br><span class="line"><span class="symbol">8 </span>mice</span><br><span class="line"><span class="symbol">9 </span>mice</span><br><span class="line"><span class="symbol">10 </span>mice</span><br></pre></td></tr></table></figure><p>By the time you finished entering <code>9 mice</code>, a result is output</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">24</span>, mice)</span><br></pre></td></tr></table></figure></li><li><p>Keyed and Processing Time based Session Window</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data.flatMap(<span class="keyword">new</span> LineSplitter())</span><br><span class="line">    .keyBy(<span class="number">1</span>)</span><br><span class="line">    <span class="comment">// the session window is set to 5 seconds, the sum will be calculated if no more data in the 5 seconds</span></span><br><span class="line">    .window(ProcessingTimeSessionWindows.withGap(Time.seconds(<span class="number">5</span>))) </span><br><span class="line">    .sum(<span class="number">0</span>)</span><br><span class="line">    .print();</span><br></pre></td></tr></table></figure><p>Enter the following in the terminal window, then wait for 5 seconds</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">5 </span>lions</span><br></pre></td></tr></table></figure><p>The output will be printed in approximate 5 seconds</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">5</span>,lions)</span><br></pre></td></tr></table></figure><p>Try different input and watch out the output carefully. You might wonder what’s the difference between the tumbling window and the session window.</p><blockquote><p><a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/windows.html" target="_blank" rel="noopener">The session windows assigner groups elements by sessions of activity. Session windows do not overlap and do not have a fixed start and end time, in contrast to tumbling windows and sliding windows. Instead a session window closes when it does not receive elements for a certain period of time, i.e., when a gap of inactivity occurred. A session window assigner can be configured with either a static session gap or with a session gap extractor function which defines how long the period of inactivity is. When this period expires, the current session closes and subsequent elements are assigned to a new session window.</a></p></blockquote></li><li><p>Non-Keyed and Processing Time based windowAll Window</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataStream.flatMap(<span class="keyword">new</span> LineSplitter())</span><br><span class="line">        .timeWindowAll(Time.seconds(<span class="number">10</span>))</span><br><span class="line">        .sum(<span class="number">0</span>)</span><br><span class="line">        .print();</span><br></pre></td></tr></table></figure><p>You enter</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">3 </span>dogs</span><br><span class="line"><span class="symbol">5 </span>cats</span><br><span class="line"><span class="symbol">11 </span>lions</span><br></pre></td></tr></table></figure></li></ol><p>The output is </p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">19</span>,dogs)</span><br></pre></td></tr></table></figure><ol start="6"><li>Keyed and Event Time based Tumbling Window and Watermark<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">  env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span><br><span class="line">  DataStream&lt;WordEvent&gt; data = env.addSource(<span class="keyword">new</span> CustomSource())</span><br><span class="line">          .assignTimestampsAndWatermarks(<span class="keyword">new</span> AssignerWithPeriodicWatermarks&lt;WordEvent&gt;() &#123;</span><br><span class="line">              <span class="keyword">private</span> <span class="keyword">long</span> currentTimestamp = Long.MIN_VALUE;</span><br><span class="line">              <span class="meta">@Nullable</span></span><br><span class="line">              <span class="meta">@Override</span></span><br><span class="line">              <span class="function"><span class="keyword">public</span> Watermark <span class="title">getCurrentWatermark</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                  <span class="keyword">return</span> <span class="keyword">new</span> Watermark(currentTimestamp == Long.MIN_VALUE ? Long.MIN_VALUE : currentTimestamp - <span class="number">1</span>);</span><br><span class="line">              &#125;</span><br><span class="line"></span><br><span class="line">              <span class="meta">@Override</span></span><br><span class="line">              <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(WordEvent element, <span class="keyword">long</span> previousElementTimestamp)</span> </span>&#123;</span><br><span class="line">                  <span class="keyword">if</span> (element.getTimestamp() &gt; currentTimestamp) &#123;</span><br><span class="line">                      <span class="keyword">this</span>.currentTimestamp = element.getTimestamp();</span><br><span class="line">                  &#125;</span><br><span class="line">                  <span class="keyword">return</span> currentTimestamp;</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;);</span><br><span class="line"></span><br><span class="line">  data.keyBy(WordEvent::getWord)</span><br><span class="line">          .timeWindow(Time.seconds(<span class="number">5</span>))</span><br><span class="line">          .sum(<span class="string">"count"</span>)</span><br><span class="line">          .print();</span><br><span class="line"></span><br><span class="line">  env.execute(<span class="string">"keyed and event based tumbling window"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>Each 5 seconds, the terminal will print some output, the output might look like<figure class="highlight erlang-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">9&gt; </span>WordEvent(word=flinkinpracticeF, count=<span class="number">12</span>, timestamp=<span class="number">1571171275592</span>)</span><br><span class="line"><span class="meta">8&gt; </span>WordEvent(word=flinkinpracticeA, count=<span class="number">8</span>, timestamp=<span class="number">1571171277598</span>)</span><br><span class="line"><span class="meta">8&gt; </span>WordEvent(word=flinkinpracticeA, count=<span class="number">5</span>, timestamp=<span class="number">1571171283620</span>)</span><br><span class="line"><span class="meta">9&gt; </span>WordEvent(word=flinkinpracticeF, count=<span class="number">1</span>, timestamp=<span class="number">1571171280610</span>)</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;em&gt;Time&lt;/em&gt; and &lt;em&gt;Windows&lt;/em&gt; are two basic and important concepts in Apache Flink. Apache Flink is able to handle:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Processing Time&lt;/li&gt;
&lt;li&gt;Event Time&lt;/li&gt;
&lt;li&gt;Ingestion Time&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;On the other hand, Apache Flink provides different &lt;em&gt;windows&lt;/em&gt; oepration:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Tumbling Window&lt;/li&gt;
&lt;li&gt;Sliding Window&lt;/li&gt;
&lt;li&gt;Session Window&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
    
      <category term="Flink" scheme="//flinkinpractice.com/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Stream Split</title>
    <link href="//flinkinpractice.com/2019/09/21/Stream-Split/"/>
    <id>//flinkinpractice.com/2019/09/21/Stream-Split/</id>
    <published>2019-09-21T13:10:51.000Z</published>
    <updated>2019-11-02T13:14:58.899Z</updated>
    
    <content type="html"><![CDATA[<p>Here is a use case. Our data source is a stream of alerts. The alert has two properties: one is where it is from, docker container, middle ware or server health check, the other is the alert status, still warning or recovering. In the end, we want to pay close attention to the recovering status of alert coming from middle ware. </p><p>Here is the code snippet for tackling this problem.</p><!-- The following diagram shows how we want to tackle the problem. --><a id="more"></a><!-- [split diagram](../../images/part-ii/chapter8/split-diagram.jpg) --><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FilterFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.collector.selector.OutputSelector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SplitStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataStreamSplit</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> ParameterTool params = ParameterTool.fromArgs(args);</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> rate = params.getLong(<span class="string">"rate"</span>, <span class="number">3L</span>);</span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;Tuple2&lt;String, String&gt;&gt; alertsStream = AlertSource.getSource(env, rate);</span><br><span class="line"></span><br><span class="line">        SplitStream&lt;Tuple2&lt;String, String&gt;&gt; splitStream = alertsStream.split(<span class="keyword">new</span> OutputSelector&lt;Tuple2&lt;String, String&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Iterable&lt;String&gt; <span class="title">select</span><span class="params">(Tuple2&lt;String, String&gt; alertTuple)</span> </span>&#123;</span><br><span class="line">                List&lt;String&gt; tags = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">                <span class="keyword">switch</span> (alertTuple.f0) &#123;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">"DOCKER"</span>:</span><br><span class="line">                        tags.add(<span class="string">"DOCKER"</span>);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">"MIDDLE_WARE"</span>:</span><br><span class="line">                        tags.add(<span class="string">"MIDDLE_WARE"</span>);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">"HEALTH_CHECK"</span>:</span><br><span class="line">                        tags.add(<span class="string">"HEALTH_CHECK"</span>);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span> tags;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;Tuple2&lt;String, String&gt;&gt; middlewareStream = splitStream.select(<span class="string">"MIDDLE_WARE"</span>);</span><br><span class="line"></span><br><span class="line">        middlewareStream.filter(<span class="keyword">new</span> FilterFunction&lt;Tuple2&lt;String, String&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Tuple2&lt;String, String&gt; alertTuple)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> alertTuple.f1.equalsIgnoreCase(<span class="string">"RECOVERING"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).print();</span><br><span class="line"></span><br><span class="line">        env.execute(<span class="string">"Split and filter with Flink"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>If you run this piece of code with IntelliJ, it might show that <code>SplitStream</code> class has been marked as deprecated. To achieve the same goal, Flink now suggests to use <code>Side Ouput</code>. </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Here is a use case. Our data source is a stream of alerts. The alert has two properties: one is where it is from, docker container, middle ware or server health check, the other is the alert status, still warning or recovering. In the end, we want to pay close attention to the recovering status of alert coming from middle ware. &lt;/p&gt;
&lt;p&gt;Here is the code snippet for tackling this problem.&lt;/p&gt;
&lt;!-- The following diagram shows how we want to tackle the problem. --&gt;
    
    </summary>
    
    
    
      <category term="Flink" scheme="//flinkinpractice.com/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Run Flink App Jar</title>
    <link href="//flinkinpractice.com/2019/08/29/Run-Flink-App-Jar/"/>
    <id>//flinkinpractice.com/2019/08/29/Run-Flink-App-Jar/</id>
    <published>2019-08-29T12:35:26.000Z</published>
    <updated>2019-11-01T03:50:30.255Z</updated>
    
    <content type="html"><![CDATA[<p>For Flink application, there is one way to run a built jar file, also this is the way Flink recommended</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flink run -c com.flink.streamwordcount ./target/your-target-jar-file.jar</span><br></pre></td></tr></table></figure><a id="more"></a><p><code>com.flink.streamwordcount</code> is the main class of your Flink application.<br>Since we are used to run jar file with Java in this fashion. Just for fun, how could we still use this approach? </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -jar YOUR-TARGET-JAR-FILE.jar</span><br></pre></td></tr></table></figure><p>To do so, we have modified your <code>pom.xml</code> a little bit, assumed you are using Flink template to generate Intelli J project<br>First of all, you might have to take <code>org.slf4j.*</code> and <code>log4j</code> from the exclude list</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">artifactSet</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>org.apache.flink:force-shading<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>com.google.code.findbugs:jsr305<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">      <span class="comment">&lt;!--&lt;exclude&gt;org.slf4j:*&lt;/exclude&gt;--&gt;</span></span><br><span class="line">      <span class="comment">&lt;!--&lt;exclude&gt;log4j:*&lt;/exclude&gt;--&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">artifactSet</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Second, you need to add the following line in the <code>&lt;transformers&gt;</code> section.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">transformer</span> <span class="attr">implementation</span>=<span class="string">"org.apache.maven.plugins.shade.resource.AppendingTransformer"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">resource</span>&gt;</span>reference.conf<span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">transformer</span>&gt;</span></span><br></pre></td></tr></table></figure><p>You can read official documentation of <a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/projectsetup/dependencies.html#appendix-template-for-building-a-jar-with-dependencies" target="_blank" rel="noopener">Configuring Dependencies, Connectors, Libraries</a> to understand more.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;For Flink application, there is one way to run a built jar file, also this is the way Flink recommended&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;flink run -c com.flink.streamwordcount ./target/your-target-jar-file.jar&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
    
      <category term="Flink" scheme="//flinkinpractice.com/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink Batch Processing: Word Count</title>
    <link href="//flinkinpractice.com/2019/08/01/Flink-Batch-Processing-Word-Count/"/>
    <id>//flinkinpractice.com/2019/08/01/Flink-Batch-Processing-Word-Count/</id>
    <published>2019-08-02T02:30:04.000Z</published>
    <updated>2019-11-02T02:36:36.654Z</updated>
    
    <content type="html"><![CDATA[<p>By the time you create your first Flink application with Intelli J, you might have noticed a <code>BatchJob</code> skeleton Java class has been created. We will use this class to do a word count in a batch way. In this example, we predefine a paragraph of words, let our application count the occurrences of the words. Here is the code:</p><a id="more"></a><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.ReduceFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.ExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Flink Word Count Batch Job.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BatchJob</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">env.fromElements(WORDS) <span class="comment">// Specify the data source</span></span><br><span class="line">.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;  <span class="comment">// use regular expression to split words</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String s, org.apache.flink.util.Collector&lt;Tuple2&lt;String, Integer&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">String[] splits = s.toLowerCase().split(<span class="string">"\\W+"</span>);</span><br><span class="line"><span class="keyword">for</span> (String split : splits) &#123;</span><br><span class="line"><span class="keyword">if</span> (split.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">collector.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(split, <span class="number">1</span>));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line">.groupBy(<span class="number">0</span>) <span class="comment">// group same word</span></span><br><span class="line">.reduce(<span class="keyword">new</span> ReduceFunction&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;  <span class="comment">// count word</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">reduce</span><span class="params">(Tuple2&lt;String, Integer&gt; value1, Tuple2&lt;String, Integer&gt; value2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(value1.f0, value1.f1 + value2.f1);</span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line">.print(); <span class="comment">// print to stdout</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String[] WORDS = <span class="keyword">new</span> String[]&#123;</span><br><span class="line"><span class="string">"To be, or not to be,--that is the question:--"</span>,</span><br><span class="line"><span class="string">"Whether 'tis nobler in the mind to suffer"</span>,</span><br><span class="line"><span class="string">"The slings and arrows of outrageous fortune"</span>,</span><br><span class="line"><span class="string">"Or to take arms against a sea of troubles,"</span>,</span><br><span class="line"><span class="string">"And by opposing end them?--To die,--to sleep,--"</span></span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Run the <code>BatchJob.main()</code> within IntelliJ, and you are expected to see the following output in the terminal window:</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="number">11</span>:<span class="number">40</span>:<span class="number">26</span>,<span class="number">856</span> INFO  org.apache.flink.runtime.blob.TransientBlobCache              - Shutting down BLOB cache</span><br><span class="line"><span class="number">11</span>:<span class="number">40</span>:<span class="number">26</span>,<span class="number">857</span> INFO  org.apache.flink.runtime.blob.BlobServer                      - Stopped BLOB server at <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">54175</span></span><br><span class="line"><span class="number">11</span>:<span class="number">40</span>:<span class="number">26</span>,<span class="number">857</span> INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService              - Stopped Akka RPC service.</span><br><span class="line">(arrows,<span class="number">1</span>)</span><br><span class="line">(be,<span class="number">2</span>)</span><br><span class="line">(nobler,<span class="number">1</span>)</span><br><span class="line">(of,<span class="number">2</span>)</span><br><span class="line">(a,<span class="number">1</span>)</span><br><span class="line">(<span class="keyword">in</span>,<span class="number">1</span>)</span><br><span class="line">(mind,<span class="number">1</span>)</span><br><span class="line">(<span class="keyword">or</span>,<span class="number">2</span>)</span><br><span class="line">(suffer,<span class="number">1</span>)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>Isn’t this code self-explanatory?</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;By the time you create your first Flink application with Intelli J, you might have noticed a &lt;code&gt;BatchJob&lt;/code&gt; skeleton Java class has been created. We will use this class to do a word count in a batch way. In this example, we predefine a paragraph of words, let our application count the occurrences of the words. Here is the code:&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Flink" scheme="//flinkinpractice.com/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Your First Flink Application: Word Count</title>
    <link href="//flinkinpractice.com/2019/07/29/Your-First-Flink-Application-Word-Count/"/>
    <id>//flinkinpractice.com/2019/07/29/Your-First-Flink-Application-Word-Count/</id>
    <published>2019-07-30T00:12:50.000Z</published>
    <updated>2019-11-01T03:50:01.875Z</updated>
    
    <content type="html"><![CDATA[<p>The first application is the famous <em>word count</em> big data application. The count of same word will be added up. For example, your input looks like this:</p><a id="more"></a><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">flink streaming <span class="built_in">word</span> <span class="built_in">count</span> example</span><br><span class="line"><span class="built_in">word</span></span><br><span class="line"><span class="built_in">count</span></span><br><span class="line">example</span><br><span class="line">streaming</span><br><span class="line">flink</span><br></pre></td></tr></table></figure><p>You are expected to see</p><figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">flink</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="name">streaming</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="name">word</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="name"><span class="builtin-name">count</span></span>, <span class="number">1</span>)</span><br><span class="line">(<span class="name">example</span>, <span class="number">1</span>)</span><br><span class="line">(<span class="name">word</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="name"><span class="builtin-name">count</span></span>, <span class="number">2</span>)</span><br><span class="line">(<span class="name">example</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="name">streaming</span>, <span class="number">2</span>)</span><br><span class="line">(<span class="name">flink</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>The order of output might be different from the above. In this example, you will enter words and press enter in a terminal, your application counts the number of words.</p><h2 id="Coding-with-Intelli-J-IDE"><a href="#Coding-with-Intelli-J-IDE" class="headerlink" title="Coding with Intelli J IDE"></a>Coding with Intelli J IDE</h2><p>Open your Intelli J IDE, start from menu <code>File</code>, choose <code>New Project</code>, find the following information from the window<br><img src="https://mlflowexperiments.blob.core.windows.net/flink-in-practice-blog/chapter-2/chapter-2-new-flink-project.png" alt="new flink project"><br>Then, put <code>groupId</code> and <code>artifactId</code> of your choice in the next window.<br>The next step is to create a new Java class, name it <code>SocketTextStreamWordCount</code>. Type the following code</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SocketTextStreamWordCount</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// validating input</span></span><br><span class="line">        <span class="keyword">if</span> (args.length != <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">"USAGE:\nSocketTextStreamWordCount &lt;hostname&gt; &lt;port&gt;"</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        String hostname = args[<span class="number">0</span>];</span><br><span class="line">        Integer port = Integer.parseInt(args[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// set up the streaming execution environment</span></span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// acquiring input</span></span><br><span class="line">        DataStreamSource&lt;String&gt; stream = env.socketTextStream(hostname, port);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// counting</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = stream.flatMap(<span class="keyword">new</span> LineSplitter())</span><br><span class="line">                .keyBy(<span class="number">0</span>)</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        sum.print();</span><br><span class="line"></span><br><span class="line">        env.execute(<span class="string">"Java WordCount from Sock"</span> +</span><br><span class="line">                <span class="string">""</span> +</span><br><span class="line">                <span class="string">"etTextStream Example"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">LineSplitter</span> <span class="keyword">implements</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String s, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            String[] tokens = s.toLowerCase().split(<span class="string">"\\W+"</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (String token: tokens) &#123;</span><br><span class="line">                <span class="keyword">if</span> (token.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    collector.collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(token, <span class="number">1</span>));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>That’s all the code you need to write. Now we need to build and run the project. You can use the integrated <code>Terminal</code> of IntelliJ to enter </p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean package -<span class="module-access"><span class="module"><span class="identifier">Dmaven</span>.</span></span>test.skip=<span class="literal">true</span></span><br></pre></td></tr></table></figure><p>Hopefully, you will see result like this:<br><img src="https://mlflowexperiments.blob.core.windows.net/flink-in-practice-blog/chapter-2/chapter-2-flink-application-build-success.png" alt="a successful build"><br>and your build <code>jar</code> file should be located at</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./target/streaming-<span class="built_in">word</span>-<span class="built_in">count</span><span class="number">-1.0</span>-SNAPSHOT.jar</span><br></pre></td></tr></table></figure><h3 id="Test-Your-Application"><a href="#Test-Your-Application" class="headerlink" title="Test Your Application"></a>Test Your Application</h3><p>In the same window, run the following to start the <a href="https://en.wikipedia.org/wiki/Netcat" target="_blank" rel="noopener">netcat</a> client:</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc -l <span class="number">9000</span></span><br></pre></td></tr></table></figure><p>Then start to type the following</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">flink streaming <span class="built_in">word</span> <span class="built_in">count</span> example</span><br><span class="line"><span class="built_in">word</span></span><br><span class="line"><span class="built_in">count</span></span><br><span class="line">example</span><br><span class="line">streaming</span><br><span class="line">flink</span><br></pre></td></tr></table></figure><p>Don’t worry about that nothing happened every time you type and hit enter because we have not run our Flink application yet.</p><p>If you have not set Flink to your <code>PATH</code>, you need to enter the following command in a new terminal window</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flink run -c com.flinkinpratice.SocketTextStreamWordCount ./target/streaming-word-count<span class="number">-1.0</span>-SNAPSHOT.jar <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> <span class="number">9000</span></span><br></pre></td></tr></table></figure><p>If you have defined a different <code>groupId</code>, replace with yours in the above command.</p><p>Head to <code>http://localhost:8081</code>, you will get a little bit excited.</p><p><img src="https://mlflowexperiments.blob.core.windows.net/flink-in-practice-blog/chapter-2/chapter-2-word-count-web-ui-result.png" alt="word count result in Web UI"><br>We encourage you to click around to understand more what the web UI has to offer. The new web UI is quite different from the previous version.<br><img src="https://mlflowexperiments.blob.core.windows.net/flink-in-practice-blog/chapter-2/chapter-2-web-ui-detail.png" alt="word count details">. We will go over the details in the later chapter.</p><p>Now we need another terminal window to see the word count result. Find your Flink installation directory, use this:</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -f /usr/local/Cellar/apache-flink/<span class="number">1.9</span><span class="number">.0</span>/libexec/log/flink-l0j011d-taskexecutor<span class="number">-0</span>-m-c02xd0fljgh7.<span class="keyword">out</span></span><br></pre></td></tr></table></figure><p>If you look at the directory of <code>/usr/local/Cellar/apache-flink/1.9.0/libexec/log/</code>, there are quite a few files of <code>.log</code> and <code>.out</code>. Pick the ones without suffixes of <code>.1</code>, <code>.2</code>, etc.<br>What we saw? </p><figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(<span class="name">flink</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name">streaming</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name">word</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name"><span class="builtin-name">count</span></span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name">example</span>,<span class="number">1</span>)</span><br><span class="line">(<span class="name">word</span>,<span class="number">2</span>)</span><br><span class="line">(<span class="name"><span class="builtin-name">count</span></span>,<span class="number">2</span>)</span><br><span class="line">(<span class="name">example</span>,<span class="number">2</span>)</span><br><span class="line">(<span class="name">streaming</span>,<span class="number">2</span>)</span><br><span class="line">(<span class="name">flink</span>,<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>Add more word in your <code>nc</code> terminal window, see the output in action.</p><figure class="highlight"><figcaption><span>window</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batch processing example</span><br></pre></td></tr></table></figure><p>Your <code>tail</code> window changes to`</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">(batch,<span class="number">1</span>)</span><br><span class="line">(processing,<span class="number">1</span>)</span><br><span class="line">(example,<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>In this example, we show how you can code your first streaming application: word count. We started from a IntelliJ Flink template, then write the core code, buid the application. Use <code>netcat</code> to stream your input and see the result in terminal and Flink Web UI.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The first application is the famous &lt;em&gt;word count&lt;/em&gt; big data application. The count of same word will be added up. For example, your input looks like this:&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Flink" scheme="//flinkinpractice.com/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Set Up Flink on Mac OS X</title>
    <link href="//flinkinpractice.com/2019/07/28/Set-Up-Flink-on-Mac-OS-X/"/>
    <id>//flinkinpractice.com/2019/07/28/Set-Up-Flink-on-Mac-OS-X/</id>
    <published>2019-07-29T04:01:14.000Z</published>
    <updated>2019-11-01T03:47:49.876Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/getting-started/tutorials/local_setup.html#setup-download-and-start-flink" target="_blank" rel="noopener">Flink Official Documentation</a> has the details of set up Flink on Mac OS X. You should be able to get it working without problem. </p><p>In this tutorial, we walk you through the installation with <em>Homebrew</em>.</p><a id="more"></a><h2 id="Environment-Preparation"><a href="#Environment-Preparation" class="headerlink" title="Environment Preparation"></a>Environment Preparation</h2><ol><li><p>Java Environment<br>Let’s make sure you have <code>Java</code> installed. We recommend <code>Java 8</code>. Open your terminal, enter</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -<span class="built_in">version</span></span><br></pre></td></tr></table></figure></li><li><p>Install Flink<br>Let’s use <code>homebrew</code> install Flink. In terminal, type</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">brew </span><span class="keyword">install </span>apache-flink</span><br></pre></td></tr></table></figure><p>To make sure it has been installed properly, type</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flink <span class="comment">--version</span></span><br></pre></td></tr></table></figure><p>My terminal tells me</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Version: <span class="number">1.9</span><span class="number">.0</span>, Commit ID: <span class="number">9</span>c32ed9</span><br></pre></td></tr></table></figure><p>Good enough. </p></li><li><p>Start Flink Cluster<br>In terminal, enter</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$/usr/<span class="built_in">local</span>/Cellar/apache-flink/<span class="number">1.9</span><span class="number">.0</span>/libexec/bin/<span class="built_in">start</span>-cluster.sh</span><br><span class="line">Starting cluster.</span><br><span class="line">Starting standalonesession daemon <span class="keyword">on</span> <span class="title">host</span> <span class="title">d-c02xw0aljgh7</span>.</span><br><span class="line">Starting taskexecutor daemon <span class="keyword">on</span> <span class="title">host</span> <span class="title">d-c02xw0aljgh7</span>.</span><br></pre></td></tr></table></figure><p>It is a good idea to write down the <code>bin</code> directory somewhere or so you can find it easily next time, or set it to <code>path</code> of your Mac OS X </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/Cellar/apache-flink/1.9.0/libexec/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">source</span> .bash_profile  // <span class="keyword">in</span> <span class="keyword">case</span> you use .bash_profile</span><br></pre></td></tr></table></figure><p>so you can just run </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">l0j011d$ <span class="keyword">start</span>-cluster.sh</span><br><span class="line"><span class="keyword">Starting</span> cluster.</span><br><span class="line"><span class="keyword">Starting</span> standalonesession daemon <span class="keyword">on</span> host d-c02xw0aljgh7.</span><br><span class="line"><span class="keyword">Starting</span> taskexecutor daemon <span class="keyword">on</span> host d-c02xw0aljgh7.</span><br></pre></td></tr></table></figure></li></ol><p>Take one more look at the <code>bin</code> directory, you will quickly learn how to stop the running cluster</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">stop</span>-cluster.sh</span><br><span class="line">Stopping taskexecutor daemon (pid: <span class="number">85962</span>) <span class="keyword">on</span> <span class="title">host</span> <span class="title">d-c02xw0aljgh7</span>.</span><br><span class="line">Stopping standalonesession daemon (pid: <span class="number">85533</span>) <span class="keyword">on</span> <span class="title">host</span> <span class="title">d-c02xw0aljgh7</span>.</span><br></pre></td></tr></table></figure><p>We will come back later for other scripts.</p><ol start="4"><li>Web UI<br>Use your favorite web browser, open <code>http://localhost:8081</code>. Happy to see some UI but not too exciting. We need to add some jobs.<br><img src="https://mlflowexperiments.blob.core.windows.net/flink-in-practice-blog/chapter-2-initial-flink-web-ui.png" alt="initial flink web UI"></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://ci.apache.org/projects/flink/flink-docs-release-1.9/getting-started/tutorials/local_setup.html#setup-download-and-start-flink&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Flink Official Documentation&lt;/a&gt; has the details of set up Flink on Mac OS X. You should be able to get it working without problem. &lt;/p&gt;
&lt;p&gt;In this tutorial, we walk you through the installation with &lt;em&gt;Homebrew&lt;/em&gt;.&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Flink" scheme="//flinkinpractice.com/tags/Flink/"/>
    
  </entry>
  
</feed>
